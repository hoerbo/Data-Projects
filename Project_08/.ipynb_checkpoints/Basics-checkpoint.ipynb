{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "In this project a spam classificator is built using a multinominal naive bayes algorithm with laplace smoothing. The algorithm is trained and tested on a dataset of 5572 (human) classified sms message which can be found [here](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical principles\n",
    "\n",
    "Under the assumption of conditional independence of words $w_1,w_2, ..., w_n$ in a message, the expanded bayes algorithm reduces to the naive bayes algorithm. To classify a message according to *Spam* vs. *Ham* (non-spam), the two following probabilities are calculated and compared case-by-case:\n",
    "\n",
    "$$\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}$$\n",
    "\n",
    "$$\\begin{equation}\n",
    "    P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "    \\end{equation}$$\n",
    "    \n",
    "The classification will be performed as follow:\n",
    "- $P(Spam | w_1,w_2, ..., w_n) > P(Ham | w_1,w_2, ..., w_n)$ : **Spam**\n",
    "- $P(Spam | w_1,w_2, ..., w_n) < P(Ham | w_1,w_2, ..., w_n)$ : **Not spam**\n",
    "- $P(Spam | w_1,w_2, ..., w_n) = P(Ham | w_1,w_2, ..., w_n)$ : **Undefined (needs human assistance)**\n",
    "    \n",
    "All parameters in the two equations above are calculated initially using a training set. The calculation performed *online* for a new message simplifies to a multiplicative combination of these parameters (depending on the words the message consists of).\n",
    "\n",
    "P(Spam) is given by the number of spam messages in the training set divided by the total number of messages. P(Ham) is calculated by 1 - P(Spam) accordingly. P(w<sub>i</sub>|Spam) is given by:\n",
    "\n",
    "$$\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam}}{N_{Spam}}\n",
    "\\end{equation}$$\n",
    "\n",
    "with N<sub>(w<sub>i</sub>|Spam)</sub> as the total number of times the word $w_i$ occurs in all spam messages of the training set and N<sub>Spam</sub> as the total number of words in all spam messages. Words not occuring in the vocabulary (all unique words in the trainin set) will be ignored. However, there is an exception for words only occuring in one subset (regarding to *Spam* vs. *Ham*) and missing in the other. Since the probability of the missing word occuring in the subset is zero, the whole probability of the message yields to zero due to the multiplicative operations in the first two equations. To solve this issue the additive (laplace) smoothing technique is introduced:\n",
    "\n",
    "$$\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}$$\n",
    "\n",
    "using $\\alpha = 1$ and N<sub>Vocabulary</sub> as the number of unique words in the vocabulary.\n",
    "\n",
    "P(w<sub>i</sub>|Ham) is given accordingly:\n",
    "\n",
    "$$\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}$$\n",
    "\n",
    "According to this theoretical background the spam filter can now be developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data set and sample training and test sets\n",
    "\n",
    "First the dataset is read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                     SMS\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SMSSpamCollection = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "SMSSpamCollection.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 5572 rows and two columns `Label` and `SMS`. The latter contains the message while the former classifies the message as `spam` or `ham` (non-spam). The number of spam messages in the dataset is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMSSpamCollection['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and calculates to 13% of the total messages.\n",
    "\n",
    "Now the data set is split into a training set (approx. 80% of the original dataset) and a test set. \n",
    "\n",
    "First the data set is randomized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SMSSpamCollection = SMSSpamCollection.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then split into both parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amount_spam = int(0.8 * len(SMSSpamCollection))\n",
    "amount_ham = len(SMSSpamCollection) - amount_spam\n",
    "\n",
    "training_set = SMSSpamCollection.iloc[:amount_spam]\n",
    "training_set = training_set.reset_index(drop=True)\n",
    "\n",
    "test_set = SMSSpamCollection.iloc[amount_spam:]\n",
    "test_set = test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of the sampling process can be demonstrated by calculating the percentage of spam in the two new datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13461969934933812\n",
      "0.13183856502242153\n"
     ]
    }
   ],
   "source": [
    "spam_training = training_set['Label'].value_counts()['spam'] / amount_spam\n",
    "spam_test = test_set['Label'].value_counts()['spam'] / amount_ham\n",
    "\n",
    "print(spam_training)\n",
    "print(spam_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the percentage of spam is comparable to the percentage of spam in the original data set the sampling was performed reasonably.\n",
    "\n",
    "Furthermore the data sets are cleaned by removing all punctuation and transforming every word to lower case. First the last five rows of `training_set` are plotted for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>ham</td>\n",
       "      <td>How about clothes, jewelry, and trips?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later in meeting any thing re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ham</td>\n",
       "      <td>Babe! I fucking love you too !! You know? Fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>spam</td>\n",
       "      <td>U've been selected to stay in 1 of 250 top Bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hello my boytoy ... Geeee I miss you already a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "4452   ham             How about clothes, jewelry, and trips?\n",
       "4453   ham  Sorry, I'll call later in meeting any thing re...\n",
       "4454   ham  Babe! I fucking love you too !! You know? Fuck...\n",
       "4455  spam  U've been selected to stay in 1 of 250 top Bri...\n",
       "4456   ham  Hello my boytoy ... Geeee I miss you already a..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data set `training_set` is cleaned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>ham</td>\n",
       "      <td>how about clothes  jewelry  and trips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>sorry  i ll call later in meeting any thing re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ham</td>\n",
       "      <td>babe  i fucking love you too    you know  fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>spam</td>\n",
       "      <td>u ve been selected to stay in 1 of 250 top bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>hello my boytoy     geeee i miss you already a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "4452   ham             how about clothes  jewelry  and trips \n",
       "4453   ham  sorry  i ll call later in meeting any thing re...\n",
       "4454   ham  babe  i fucking love you too    you know  fuck...\n",
       "4455  spam  u ve been selected to stay in 1 of 250 top bri...\n",
       "4456   ham  hello my boytoy     geeee i miss you already a..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub('\\W',' ',text) #the \\W ('not word') character class is substituted by ' '\n",
    "\n",
    "training_set['SMS'] = training_set['SMS'].apply(remove_punctuation).str.lower()\n",
    "\n",
    "training_set.tail()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach is performed for the `test_set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set['SMS'] = test_set['SMS'].apply(remove_punctuation).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the vocabulary\n",
    "\n",
    "The vocabulary contains the set of unique words in the training set and will be populated in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72423\n",
      "7782\n"
     ]
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split() #split strings at the space characters\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for message in training_set['SMS']:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)      \n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary = set(vocabulary) #transform list to set to remove duplicates\n",
    "vocabulary = list(vocabulary)\n",
    "print(len(vocabulary))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary contains 7782 unique words and is used to create the matrix *word_counts_per_sms* of size 5572 x 7784.\n",
    "Every unique word is represented as a column while the rows are populated by the messages. The two extra columns are used to concatenate the `Label` and `SMS` columns from the original data set. An example for the structure of the matrix is given below.\n",
    "\n",
    "The matrix is initialized as a dictionary and then converted to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7784 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary} #init the dict with zeros\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "word_counts_per_sms = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "word_counts_matrix = pd.concat([training_set, word_counts_per_sms], axis=1) #add 'Label' and 'SMS' from the original data set\n",
    "word_counts_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the matrix can be interpreted by observing the last row in the section above. The message \"i forgot 2 ask ü all smth there s a card on da present lei how ü all want 2 write smth or sign on it\" leads to a population of the column `ü` by 2 since the character `ü` is represented twice in the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spam filter\n",
    "\n",
    "The spam filter is defined as the function `classify()`.\n",
    "However, first the parameters are generated as described in the section about the theoretical principles.\n",
    "\n",
    "P(Spam) is calculated by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13461969934933812\n"
     ]
    }
   ],
   "source": [
    "P_Spam = sum(word_counts_matrix['Label'] == 'spam') / len(word_counts_matrix)\n",
    "print(P_Spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly P(Ham) is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653803006506618\n"
     ]
    }
   ],
   "source": [
    "P_Ham = 1 - P_Spam\n",
    "print(P_Ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N<sub>Spam</sub> can be calculated by logical indexing into *word_counts_matrix* ignoring the first two rows and summing all values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15190\n"
     ]
    }
   ],
   "source": [
    "N_Spam = word_counts_matrix[word_counts_matrix['Label'] == 'spam'].iloc[:,2:].sum().sum()\n",
    "print(N_Spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N<sub>Ham</sub> is given accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57233\n"
     ]
    }
   ],
   "source": [
    "N_Ham = word_counts_matrix[word_counts_matrix['Label'] == 'ham'].iloc[:,2:].sum().sum()\n",
    "print(N_Ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N<sub>Vocabulary</sub> is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_Vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use laplace smoothing the constant $\\alpha$ is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the probabilities P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham) are calculated based on the unique words in the vocabulary and saved in dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P_word_given_spam = {} #save probabilities as key-value pairs\n",
    "P_word_given_ham = {}\n",
    "\n",
    "\n",
    "for word in vocabulary: #initialize dictionaries with unique words from vocabulary\n",
    "    if word not in P_word_given_spam:\n",
    "        P_word_given_spam[word] = 0\n",
    "    if word not in P_word_given_ham:\n",
    "        P_word_given_ham[word] = 0 \n",
    "\n",
    "word_counts_matrix_spam = word_counts_matrix[word_counts_matrix['Label'] == 'spam'] #isolate the data sets in respect to spam and ham\n",
    "word_counts_matrix_ham = word_counts_matrix[word_counts_matrix['Label'] == 'ham'] \n",
    "\n",
    "for key in P_word_given_spam: #calculate the probabilities for every unique word\n",
    "    N_word_given_spam = word_counts_matrix_spam[key].sum()\n",
    "    P_word_given_spam[key] = (N_word_given_spam + alpha) / (N_Spam + alpha * N_Vocabulary)\n",
    "    \n",
    "for key in P_word_given_ham:\n",
    "    N_word_given_ham = word_counts_matrix_ham[key].sum()\n",
    "    P_word_given_ham[key] = (N_word_given_ham + alpha) / (N_Ham + alpha * N_Vocabulary)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the spam filter can be defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message) #format the input and convert to list of words\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    P_spam_given_message = P_Spam #initialize the probablities\n",
    "    P_ham_given_message = P_Ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in P_word_given_spam:\n",
    "            P_spam_given_message *= P_word_given_spam[word]\n",
    "        if word in P_word_given_ham:\n",
    "            P_ham_given_message *= P_word_given_ham[word]    \n",
    "   \n",
    "\n",
    "    if P_ham_given_message > P_spam_given_message: #case-by-case analysis\n",
    "        return 'ham'\n",
    "    elif P_ham_given_message < P_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the spam filter's accuracy\n",
    "\n",
    "The defined spam filter is applied to the sampled subset `test_set` and generates a classification of the messages in the new column `predicted`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>wherre s my boytoy</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess  i needa do mcat study too</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths  update to latest oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good  fingers   makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham                           wherre s my boytoy             ham\n",
       "1   ham          later i guess  i needa do mcat study too        ham\n",
       "2   ham             but i haf enuff space got like 4 mb          ham\n",
       "3  spam  had your mobile 10 mths  update to latest oran...      spam\n",
       "4   ham  all sounds good  fingers   makes it difficult ...       ham"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the accuracy can be measured by comparing the columns `predicted` and `Label`. The latter contains the *true* (human generated) labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1101\n",
      "Incorrect: 13\n",
      "Accuracy: 0.9883303411131059\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 1114\n",
    "for index, data in test_set.iterrows():\n",
    "    if data['predicted'] == test_set.loc[index, 'Label']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing the naive bayes algorithm it is assumed, that words in a message are conditional independent. This is not correct and a broad simplification. Nevertheless, the performance of the naive bayes spam filter with laplace smoothing is surprisingly good. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
